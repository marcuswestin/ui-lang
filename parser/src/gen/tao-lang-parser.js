// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {highlighting} from "../grammar/highlight.js"
const spec_Identifier = {__proto__:null,state:10, String:20, Number:24, Boolean:28}
export const parser = LRParser.deserialize({
  version: 14,
  states: "$[OVQPOOOOQO'#C_'#C_O[QPO'#C^OOQO'#Cl'#ClQVQPOOOaQPO,58xOOQO-E6j-E6jOfQPO'#CbOOQO1G.d1G.dOnQPO'#CcOOQO'#Cm'#CmOsQPO,58|OOQO,58|,58|O{QPO,58}OOQO-E6k-E6kOOQO1G.h1G.hOOQO'#Ce'#CeOOQO'#Cg'#CgOOQO'#Ci'#CiOOQO'#Cd'#CdO{QPO'#CkOOQO'#Cs'#CsOOQO1G.i1G.iO!^QPO,59VOOQO1G.q1G.q",
  stateData: "!c~OdOS~OTPO~OSTO~OeVO~OSXOj[O~Of]O~OSXOj_O~OY`O[aO^bOeVOhdO~OihO~O",
  goto: "!dhPPimPPqxt|P|P|Pt!Q!WPPPPP!^TROSTQOSQWTTe]dTYVZTc]dQSORUSQZVR^ZQf]Rgd",
  nodeNames: "âš  File StateDeclaration Keyword Identifier state StateObject StateProperty AtomicType Keyword String Keyword Number Keyword Boolean StateArray",
  maxTerm: 26,
  propSources: [highlighting],
  skippedNodes: [0],
  repeatNodeCount: 2,
  tokenData: "#w~RbX^!Zpq!Z![!]#O!c!}#T!}#O#c#P#Q#h#R#S#T#T#o#T#o#p#m#q#r#r#y#z!Z$f$g!Z#BY#BZ!Z$IS$I_!Z$I|$JO!Z$JT$JU!Z$KV$KW!Z&FU&FV!Z~!`Yd~X^!Zpq!Z#y#z!Z$f$g!Z#BY#BZ!Z$IS$I_!Z$I|$JO!Z$JT$JU!Z$KV$KW!Z&FU&FV!Z~#TOf~~#YRS~!c!}#T#R#S#T#T#o#T~#hOh~~#mOi~~#rOe~~#wOj~",
  tokenizers: [0],
  topRules: {"File":[0,1]},
  specialized: [{term: 4, get: (value) => spec_Identifier[value] || -1}],
  tokenPrec: 0
})
